{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time # just to see how fast/slow things run\n",
    "\n",
    "from scipy.misc import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is organized in folders, where in every folder there are two subfolders: ```0``` and ```1```. They respectively represent benign and malignant tumours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder  = 'IDC_regular_ps50_idx5/'\n",
    "num_positive = 78786\n",
    "num_negative = 198738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile_names contains all files names in following format:\\n\\nfile_names = [['9036_idx5_x1051_y2401_class0.png',\\n               '9036_idx5_x2951_y951_class0.png',\\n               ...],\\n               ['10257_idx5_x2101_y601_class1.png',\\n                '10257_idx5_x1651_y1251_class1.png',\\n               ...],\\n              ...]\\n               \\n\""
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, file_names = list(zip(*(list(os.walk(data_folder)))))\n",
    "file_names       = list(filter(lambda ls: len(ls) not in [0, 1], file_names))\n",
    "\n",
    "'''\n",
    "file_names contains all files names in following format:\n",
    "\n",
    "file_names = [['9036_idx5_x1051_y2401_class0.png',\n",
    "               '9036_idx5_x2951_y951_class0.png',\n",
    "               ...],\n",
    "               ['10257_idx5_x2101_y601_class1.png',\n",
    "                '10257_idx5_x1651_y1251_class1.png',\n",
    "               ...],\n",
    "              ...]\n",
    "               \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(list_file_names, test_ratio=0.2):\n",
    "    '''\n",
    "    list_file_names should be under the same format as file_names as above\n",
    "    '''\n",
    "    x_train = []\n",
    "    x_test  = []\n",
    "    \n",
    "    for ls in list_file_names:\n",
    "        \n",
    "        label      = ls[0][-5] # this list is benign or malignant\n",
    "        patient_id = re.findall('\\d+', ls[0])[0]\n",
    "        num_pics   = len(ls)\n",
    "        \n",
    "        assert label in ['0', '1']\n",
    "        \n",
    "        path = data_folder + patient_id + '/' + label + '/'\n",
    "        to_add_train, to_add_test = train_test_split(ls, test_size=test_ratio)\n",
    "        \n",
    "        x_train = x_train + [path + png for png in to_add_train]\n",
    "        x_test  = x_test + [path + png for png in to_add_test]\n",
    "    \n",
    "    \n",
    "    # We should be able to safely ignore pictures of shape (x, 50, 3) for x /0 50\n",
    "    # for computational and consistency purposes\n",
    "    x_train = list(filter(lambda pic: Image.open(pic).size == (50, 50), x_train))\n",
    "    x_test  = list(filter(lambda pic: Image.open(pic).size == (50, 50), x_test))\n",
    "    \n",
    "    random.shuffle(x_train)\n",
    "    random.shuffle(x_test)\n",
    "    \n",
    "    y_train = np.array([int(png[-5]) for png in x_train]).reshape(-1, 1)\n",
    "    y_test  = np.array([int(png[-5]) for png in x_test]).reshape(-1, 1)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 75 seconds\n",
    "x_train, y_train, x_test, y_test = get_train_test(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "\n",
    "def new_conv_layer(input,             \n",
    "                   num_input_channels,\n",
    "                   filter_size,       \n",
    "                   num_filters,       \n",
    "                   use_pooling=True): \n",
    "\n",
    "    shape   = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = new_weights(shape=shape)\n",
    "    biases  = new_biases(length=num_filters) # one for each filter\n",
    "\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape  = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat   = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "\n",
    "\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def create_batch_tuples(length, batch_size):\n",
    "    output = np.arange(0, length, batch_size)\n",
    "    \n",
    "    if output[-1] != length:\n",
    "        output = np.append(output, length)\n",
    "        \n",
    "    return list(zip(output[:-1], output[1:]))\n",
    "\n",
    "def indicator(array):\n",
    "    return np.concatenate(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x_train, y_train, x_test, batch_size):\n",
    "    '''\n",
    "    x_train is the path of the images\n",
    "    '''\n",
    "    NUM_EPOCHS = 1\n",
    "    \n",
    "    n = len(x_train)\n",
    "    \n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[None, 50, 50, 3])\n",
    "    \n",
    "    y = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "    \n",
    "    layer_conv1, weights_conv1 = new_conv_layer(input=x, num_input_channels=3, filter_size=5, num_filters=8)\n",
    "    layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1, num_input_channels=8, filter_size=7, num_filters=32)\n",
    "    layer_flat, num_features   = flatten_layer(layer_conv2)\n",
    "    \n",
    "    layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=128,\n",
    "                         use_relu=True)\n",
    "    \n",
    "    layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=128,\n",
    "                         num_outputs=1,\n",
    "                         use_relu=False)\n",
    "    # range of layer_fc2 is \\mathbb{R}^d, with d = 1\n",
    "    \n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2,\n",
    "                                                            labels=y)\n",
    "    cost      = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "    \n",
    "    batch_tuples = create_batch_tuples(len(x_train), batch_size)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for e in range(NUM_EPOCHS):\n",
    "            \n",
    "            global prediction  # for debugging\n",
    "            prediction = []\n",
    "\n",
    "            for (start, end) in batch_tuples:\n",
    "                \n",
    "                print(start)\n",
    "                x_reshaped = np.array([imread(pic) for pic in x_train[start: end]])\n",
    "                \n",
    "                sess.run([optimizer], feed_dict={x: x_reshaped,\n",
    "                                                 y: y_train[start: end]})\n",
    "        \n",
    "            for (start, end) in batch_tuples:\n",
    "                \n",
    "                x_reshaped = np.array([imread(pic) for pic in x_train[start: end]])\n",
    "                \n",
    "                global batch_preds\n",
    "                \n",
    "                batch_preds = list(indicator(layer_fc2.eval({x: x_reshaped})))\n",
    "                prediction += batch_preds\n",
    "                \n",
    "            \n",
    "            accuracy = np.mean(prediction == y_train)\n",
    "            print('Epoch {}, accuracy: {}%'.format(e, np.mean(accuracy)*100))\n",
    "        \n",
    "        batch_tuples_test = create_batch_tuples(len(x_test), batch_size)\n",
    "        '''x_test_reshaped   = x_test.reshape(-1, 50, 50, 3)\n",
    "        \n",
    "        for (start, end) in batch_tuples_test:\n",
    "            \n",
    "            batch_y_pred = y_pred.eval({x: x_test_reshaped[start:end]})\n",
    "            y_output.append(batch_y_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shamalama/Documents/Environments/ml/lib/python3.6/site-packages/ipykernel_launcher.py:46: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shamalama/Documents/Environments/ml/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, accuracy: 72.5%\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "convolutional_neural_network(x_train[:200], y_train[:200], x_test, 64)\n",
    "toc = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.108036999999968\n"
     ]
    }
   ],
   "source": [
    "print(toc - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.982608066666668"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(toc - tic)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
