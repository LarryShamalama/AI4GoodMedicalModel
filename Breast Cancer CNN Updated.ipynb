{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time # just to see how fast/slow things run\n",
    "\n",
    "from scipy.misc import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is organized in folders, where in every folder there are two subfolders: ```0``` and ```1```. They respectively represent benign and malignant tumours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder  = 'IDC_regular_ps50_idx5/'\n",
    "num_positive = 78786\n",
    "num_negative = 198738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile_names contains all files names in following format:\\n\\nfile_names = [['9036_idx5_x1051_y2401_class0.png',\\n               '9036_idx5_x2951_y951_class0.png',\\n               ...],\\n               ['10257_idx5_x2101_y601_class1.png',\\n                '10257_idx5_x1651_y1251_class1.png',\\n               ...],\\n              ...]\\n               \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, file_names = list(zip(*(list(os.walk(data_folder)))))\n",
    "file_names       = list(filter(lambda ls: len(ls) not in [0, 1], file_names))\n",
    "\n",
    "'''\n",
    "file_names contains all files names in following format:\n",
    "\n",
    "file_names = [['9036_idx5_x1051_y2401_class0.png',\n",
    "               '9036_idx5_x2951_y951_class0.png',\n",
    "               ...],\n",
    "               ['10257_idx5_x2101_y601_class1.png',\n",
    "                '10257_idx5_x1651_y1251_class1.png',\n",
    "               ...],\n",
    "              ...]\n",
    "               \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(list_file_names, test_ratio=0.2):\n",
    "    '''\n",
    "    list_file_names should be under the same format as file_names as above\n",
    "    '''\n",
    "    x_train = []\n",
    "    x_test  = []\n",
    "    \n",
    "    for ls in list_file_names:\n",
    "        \n",
    "        label      = ls[0][-5] # this list is benign or malignant\n",
    "        patient_id = re.findall('\\d+', ls[0])[0]\n",
    "        num_pics   = len(ls)\n",
    "        \n",
    "        assert label in ['0', '1']\n",
    "        \n",
    "        path = data_folder + patient_id + '/' + label + '/'\n",
    "        to_add_train, to_add_test = train_test_split(ls, test_size=test_ratio)\n",
    "        \n",
    "        x_train = x_train + [path + png for png in to_add_train]\n",
    "        x_test  = x_test + [path + png for png in to_add_test]\n",
    "    \n",
    "    \n",
    "    # We should be able to safely ignore pictures of shape (x, 50, 3) for x /0 50\n",
    "    # for computational and consistency purposes\n",
    "    x_train = list(filter(lambda pic: Image.open(pic).size == (50, 50), x_train))\n",
    "    x_test  = list(filter(lambda pic: Image.open(pic).size == (50, 50), x_test))\n",
    "    \n",
    "    random.shuffle(x_train)\n",
    "    random.shuffle(x_test)\n",
    "    \n",
    "    y_train = np.array([int(png[-5]) for png in x_train]).reshape(-1, 1)\n",
    "    y_test  = np.array([int(png[-5]) for png in x_test]).reshape(-1, 1)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "class ManualError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 75 seconds\n",
    "x_train, y_train, x_test, y_test = get_train_test(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "\n",
    "def new_conv_layer(input,             \n",
    "                   num_input_channels,\n",
    "                   filter_size,       \n",
    "                   num_filters,\n",
    "                   strides,\n",
    "                   name,\n",
    "                   use_pooling=True,\n",
    "                   max_pooling_strides=[1, 2, 2, 1]): \n",
    "\n",
    "    shape   = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = new_weights(shape=shape)\n",
    "    biases  = new_biases(length=num_filters) # one for each filter\n",
    "\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=strides,\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=max_pooling_strides,\n",
    "                               padding='SAME')\n",
    "\n",
    "    layer = tf.nn.relu(layer, name=name)\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape  = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat   = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "\n",
    "\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 name,\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases  = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(tf.add(tf.matmul(input, weights), biases), name=name)\n",
    "    else:\n",
    "        layer = tf.add(tf.matmul(input, weights), biases, name=name)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def create_batch_tuples(length, batch_size):\n",
    "    output = np.arange(0, length, batch_size)\n",
    "    \n",
    "    if output[-1] != length:\n",
    "        output = np.append(output, length)\n",
    "        \n",
    "    return list(zip(output[:-1], output[1:]))\n",
    "\n",
    "def indicator(array):\n",
    "    return np.concatenate(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x_train, y_train, x_test, y_test, batch_size):\n",
    "    '''\n",
    "    x_train is the path of the images\n",
    "    '''\n",
    "    NUM_EPOCHS = 1\n",
    "    \n",
    "    n = len(x_train)\n",
    "    \n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[None, 50, 50, 3], name='x')\n",
    "    y = tf.placeholder(dtype=tf.float32, shape=[None, 2], name='y')\n",
    "    \n",
    "    layer_conv1, weights_conv1 = new_conv_layer(input=x, \n",
    "                                                num_input_channels=3, \n",
    "                                                filter_size=5, \n",
    "                                                num_filters=8,\n",
    "                                                strides=[1, 1, 1, 1],\n",
    "                                                name='layer_conv1',\n",
    "                                                max_pooling_strides=[1, 3, 3, 1])\n",
    "    \n",
    "    layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1, \n",
    "                                                num_input_channels=8, \n",
    "                                                filter_size=5, \n",
    "                                                num_filters=16,\n",
    "                                                strides=[1, 1, 1, 1],\n",
    "                                                name='layer_conv2',\n",
    "                                                max_pooling_strides=[1, 3, 3, 1])\n",
    "    \n",
    "    layer_conv3, weights_conv3 = new_conv_layer(input=layer_conv2, \n",
    "                                                num_input_channels=16, \n",
    "                                                filter_size=5, \n",
    "                                                num_filters=32,\n",
    "                                                strides=[1, 1, 1, 1],\n",
    "                                                name='layer_conv3',\n",
    "                                                max_pooling_strides=[1, 3, 3, 1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    layer_flat, num_features = flatten_layer(layer_conv3)\n",
    "    \n",
    "    layer_fc = new_fc_layer(input=layer_flat,\n",
    "                            num_inputs=num_features,\n",
    "                            num_outputs=64,\n",
    "                            name='layer_fc',\n",
    "                            use_relu=True)\n",
    "\n",
    "    out = new_fc_layer(input=layer_fc,\n",
    "                       num_inputs=64,\n",
    "                       num_outputs=2,\n",
    "                       name='out',\n",
    "                       use_relu=False)\n",
    "    # range of out is \\mathbb{R}^d, with d = 1\n",
    "    \n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=out)\n",
    "    cost          = tf.reduce_mean(cross_entropy)\n",
    "    optimizer     = tf.train.AdagradOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    \n",
    "    batch_tuples = create_batch_tuples(len(x_train), batch_size)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for e in range(NUM_EPOCHS):\n",
    "            \n",
    "            global prediction  # for debugging\n",
    "            prediction = []\n",
    "\n",
    "            for (start, end) in batch_tuples:\n",
    "                \n",
    "                print(start)\n",
    "                x_reshaped = np.array([imread(pic) for pic in x_train[start: end]])\n",
    "                \n",
    "                sess.run([optimizer], feed_dict={x: x_reshaped,\n",
    "                                                 y: y_train[start: end]})\n",
    "        \n",
    "            batch_tuples_test = create_batch_tuples(len(x_test), batch_size)\n",
    "        \n",
    "            for (start, end) in batch_tuples_test:\n",
    "                x_test_reshaped = np.array([imread(pic) for pic in x_test[start: end]])\n",
    "                \n",
    "                batch_preds = list(out.eval({x: x_test_reshaped}))\n",
    "                prediction += batch_preds\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            accuracy = np.mean(np.argmax(prediction, axis=1) == np.argmax(y_test, axis=1))\n",
    "\n",
    "            print('Epoch {}, accuracy: {}%'.format(e, np.mean(accuracy)*100))\n",
    "        \n",
    "        '''\n",
    "        batch_tuples_test = create_batch_tuples(len(x_test), batch_size)\n",
    "        x_test_reshaped   = x_test.reshape(-1, 50, 50, 3)\n",
    "        \n",
    "        for (start, end) in batch_tuples_test:\n",
    "            \n",
    "            batch_y_pred = y_pred.eval({x: x_test_reshaped[start:end]})\n",
    "            y_output.append(batch_y_pred)'''\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, './conv_nn_breast_cancer_IMPROVED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shamalama/Documents/Environments/ml/lib/python3.6/site-packages/ipykernel_launcher.py:70: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "256\n",
      "384\n",
      "512\n",
      "640\n",
      "768\n",
      "896\n",
      "1024\n",
      "1152\n",
      "1280\n",
      "1408\n",
      "1536\n",
      "1664\n",
      "1792\n",
      "1920\n",
      "2048\n",
      "2176\n",
      "2304\n",
      "2432\n",
      "2560\n",
      "2688\n",
      "2816\n",
      "2944\n",
      "3072\n",
      "3200\n",
      "3328\n",
      "3456\n",
      "3584\n",
      "3712\n",
      "3840\n",
      "3968\n",
      "4096\n",
      "4224\n",
      "4352\n",
      "4480\n",
      "4608\n",
      "4736\n",
      "4864\n",
      "4992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shamalama/Documents/Environments/ml/lib/python3.6/site-packages/ipykernel_launcher.py:78: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, accuracy: 28.199999999999996%\n"
     ]
    }
   ],
   "source": [
    "def new_labels(y_train):\n",
    "    return np.hstack((y_train, 1 - y_train))\n",
    "\n",
    "tic = time.clock()\n",
    "convolutional_neural_network(x_train[:5000], new_labels(y_train[:5000]), x_test[:500], new_labels(y_test[:500]), 128)\n",
    "toc = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic in x_test[:20]:\n",
    "    copyfile(pic, 'breast_cancer_test_data/' + pic.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(x_test_file_path):\n",
    "    # x_test is one data point\n",
    "    # assuming it will be in color too\n",
    "    assert isinstance(x_test_file_path, str)\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "    \n",
    "\n",
    "    image = imread(x_test_file_path)\n",
    "\n",
    "    if np.shape(image) != (50, 50, 3):\n",
    "        image = image.resize((50, 50))\n",
    "\n",
    "    if np.shape(image) != (50, 50, 3):\n",
    "        print('Picture is not in colour!')\n",
    "        raise ManualError\n",
    "    \n",
    "    \n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        model = tf.train.import_meta_graph('conv_nn_breast_cancer_IMPROVED.meta')\n",
    "        model.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "        \n",
    "        x_   = loaded_graph.get_tensor_by_name('x:0')\n",
    "        out_ = loaded_graph.get_tensor_by_name('out:0')\n",
    "        \n",
    "        pred_labels = np.argmax(out_.eval({x_: np.array([image])}))\n",
    "    \n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shamalama/Documents/Environments/ml/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n",
      "INFO:tensorflow:Restoring parameters from ./conv_nn_breast_cancer_IMPROVED\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(restore_model(x_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
