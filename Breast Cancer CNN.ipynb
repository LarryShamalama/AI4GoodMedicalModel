{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time # just to see how fast/slow things run\n",
    "\n",
    "from scipy.misc import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is organized in folders, where in every folder there are two subfolders: ```0``` and ```1```. They respectively represent benign and malignant tumours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder  = 'IDC_regular_ps50_idx5/'\n",
    "num_positive = 78786\n",
    "num_negative = 198738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile_names contains all files names in following format:\\n\\nfile_names = [['9036_idx5_x1051_y2401_class0.png',\\n               '9036_idx5_x2951_y951_class0.png',\\n               ...],\\n               ['10257_idx5_x2101_y601_class1.png',\\n                '10257_idx5_x1651_y1251_class1.png',\\n               ...],\\n              ...]\\n               \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, file_names = list(zip(*(list(os.walk(data_folder)))))\n",
    "file_names       = list(filter(lambda ls: len(ls) not in [0, 1], file_names))\n",
    "\n",
    "'''\n",
    "file_names contains all files names in following format:\n",
    "\n",
    "file_names = [['9036_idx5_x1051_y2401_class0.png',\n",
    "               '9036_idx5_x2951_y951_class0.png',\n",
    "               ...],\n",
    "               ['10257_idx5_x2101_y601_class1.png',\n",
    "                '10257_idx5_x1651_y1251_class1.png',\n",
    "               ...],\n",
    "              ...]\n",
    "               \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(list_file_names, test_ratio=0.2):\n",
    "    '''\n",
    "    list_file_names should be under the same format as file_names as above\n",
    "    '''\n",
    "    x_train = []\n",
    "    x_test  = []\n",
    "    \n",
    "    for ls in list_file_names:\n",
    "        \n",
    "        label      = ls[0][-5] # this list is benign or malignant\n",
    "        patient_id = re.findall('\\d+', ls[0])[0]\n",
    "        num_pics   = len(ls)\n",
    "        \n",
    "        assert label in ['0', '1']\n",
    "        \n",
    "        path = data_folder + patient_id + '/' + label + '/'\n",
    "        to_add_train, to_add_test = train_test_split(ls, test_size=test_ratio)\n",
    "        \n",
    "        x_train = x_train + [path + png for png in to_add_train]\n",
    "        x_test  = x_test + [path + png for png in to_add_test]\n",
    "    \n",
    "    \n",
    "    # We should be able to safely ignore pictures of shape (x, 50, 3) for x /0 50\n",
    "    # for computational and consistency purposes\n",
    "    x_train = list(filter(lambda pic: Image.open(pic).size == (50, 50), x_train))\n",
    "    x_test  = list(filter(lambda pic: Image.open(pic).size == (50, 50), x_test))\n",
    "    \n",
    "    random.shuffle(x_train)\n",
    "    random.shuffle(x_test)\n",
    "    \n",
    "    y_train = np.array([int(png[-5]) for png in x_train]).reshape(-1, 1)\n",
    "    y_test  = np.array([int(png[-5]) for png in x_test]).reshape(-1, 1)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "class ManualError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 75 seconds\n",
    "x_train, y_train, x_test, y_test = get_train_test(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "\n",
    "def new_conv_layer(input,             \n",
    "                   num_input_channels,\n",
    "                   filter_size,       \n",
    "                   num_filters,  \n",
    "                   name,\n",
    "                   use_pooling=True): \n",
    "\n",
    "    shape   = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = new_weights(shape=shape)\n",
    "    biases  = new_biases(length=num_filters) # one for each filter\n",
    "\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    layer = tf.nn.relu(layer, name=name)\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape  = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat   = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "\n",
    "\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 name,\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(tf.add(tf.matmul(input, weights), biases), name=name)\n",
    "    else:\n",
    "        layer = tf.add(tf.matmul(input, weights), biases, name=name)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def create_batch_tuples(length, batch_size):\n",
    "    output = np.arange(0, length, batch_size)\n",
    "    \n",
    "    if output[-1] != length:\n",
    "        output = np.append(output, length)\n",
    "        \n",
    "    return list(zip(output[:-1], output[1:]))\n",
    "\n",
    "def indicator(array):\n",
    "    return np.concatenate(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x_train, y_train, x_test, y_test, batch_size):\n",
    "    '''\n",
    "    x_train is the path of the images\n",
    "    '''\n",
    "    NUM_EPOCHS = 1\n",
    "    \n",
    "    n = len(x_train)\n",
    "    \n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[None, 50, 50, 3], name='x')\n",
    "    y = tf.placeholder(dtype=tf.float32, shape=[None, 1], name='y')\n",
    "    \n",
    "    layer_conv1, weights_conv1 = new_conv_layer(input=x, \n",
    "                                                num_input_channels=3, \n",
    "                                                filter_size=5, \n",
    "                                                num_filters=8, \n",
    "                                                name='layer_conv1')\n",
    "    layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1, \n",
    "                                                num_input_channels=8, \n",
    "                                                filter_size=7, \n",
    "                                                num_filters=32,\n",
    "                                                name='layer_conv2')\n",
    "    layer_flat, num_features = flatten_layer(layer_conv2)\n",
    "    \n",
    "    layer_fc = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=32,\n",
    "                         name='layer_fc',\n",
    "                         use_relu=True)\n",
    "    \n",
    "    out = new_fc_layer(input=layer_fc,\n",
    "                       num_inputs=32,\n",
    "                       num_outputs=1,\n",
    "                       name='out',\n",
    "                       use_relu=False)\n",
    "    # range of out is \\mathbb{R}^d, with d = 1\n",
    "    \n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=out, labels=y)\n",
    "    cost          = tf.reduce_mean(cross_entropy)\n",
    "    optimizer     = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "    \n",
    "    batch_tuples = create_batch_tuples(len(x_train), batch_size)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for e in range(NUM_EPOCHS):\n",
    "            \n",
    "            global prediction  # for debugging\n",
    "            prediction = []\n",
    "\n",
    "            for (start, end) in batch_tuples:\n",
    "                \n",
    "                print(start)\n",
    "                x_reshaped = np.array([imread(pic) for pic in x_train[start: end]])\n",
    "                \n",
    "                sess.run([optimizer], feed_dict={x: x_reshaped,\n",
    "                                                 y: y_train[start: end]})\n",
    "        \n",
    "            '''for (start, end) in batch_tuples:\n",
    "                \n",
    "                x_test_reshaped = np.array([imread(pic) for pic in x_test[start: end]])\n",
    "                \n",
    "                batch_preds = list(indicator(out.eval({x: x_test_reshaped})))\n",
    "                prediction += batch_preds\n",
    "                \n",
    "            \n",
    "            accuracy = np.mean(prediction == y_test)\n",
    "            print('Epoch {}, accuracy: {}%'.format(e, np.mean(accuracy)*100))'''\n",
    "        \n",
    "        '''\n",
    "        batch_tuples_test = create_batch_tuples(len(x_test), batch_size)\n",
    "        x_test_reshaped   = x_test.reshape(-1, 50, 50, 3)\n",
    "        \n",
    "        for (start, end) in batch_tuples_test:\n",
    "            \n",
    "            batch_y_pred = y_pred.eval({x: x_test_reshaped[start:end]})\n",
    "            y_output.append(batch_y_pred)'''\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, './conv_nn_breast_cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shamalama/Documents/Environments/ml/lib/python3.6/site-packages/ipykernel_launcher.py:54: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "4992\n",
      "5056\n",
      "5120\n",
      "5184\n",
      "5248\n",
      "5312\n",
      "5376\n",
      "5440\n",
      "5504\n",
      "5568\n",
      "5632\n",
      "5696\n",
      "5760\n",
      "5824\n",
      "5888\n",
      "5952\n",
      "6016\n",
      "6080\n",
      "6144\n",
      "6208\n",
      "6272\n",
      "6336\n",
      "6400\n",
      "6464\n",
      "6528\n",
      "6592\n",
      "6656\n",
      "6720\n",
      "6784\n",
      "6848\n",
      "6912\n",
      "6976\n",
      "7040\n",
      "7104\n",
      "7168\n",
      "7232\n",
      "7296\n",
      "7360\n",
      "7424\n",
      "7488\n",
      "7552\n",
      "7616\n",
      "7680\n",
      "7744\n",
      "7808\n",
      "7872\n",
      "7936\n",
      "8000\n",
      "8064\n",
      "8128\n",
      "8192\n",
      "8256\n",
      "8320\n",
      "8384\n",
      "8448\n",
      "8512\n",
      "8576\n",
      "8640\n",
      "8704\n",
      "8768\n",
      "8832\n",
      "8896\n",
      "8960\n",
      "9024\n",
      "9088\n",
      "9152\n",
      "9216\n",
      "9280\n",
      "9344\n",
      "9408\n",
      "9472\n",
      "9536\n",
      "9600\n",
      "9664\n",
      "9728\n",
      "9792\n",
      "9856\n",
      "9920\n",
      "9984\n",
      "10048\n",
      "10112\n",
      "10176\n",
      "10240\n",
      "10304\n",
      "10368\n",
      "10432\n",
      "10496\n",
      "10560\n",
      "10624\n",
      "10688\n",
      "10752\n",
      "10816\n",
      "10880\n",
      "10944\n",
      "11008\n",
      "11072\n",
      "11136\n",
      "11200\n",
      "11264\n",
      "11328\n",
      "11392\n",
      "11456\n",
      "11520\n",
      "11584\n",
      "11648\n",
      "11712\n",
      "11776\n",
      "11840\n",
      "11904\n",
      "11968\n",
      "12032\n",
      "12096\n",
      "12160\n",
      "12224\n",
      "12288\n",
      "12352\n",
      "12416\n",
      "12480\n",
      "12544\n",
      "12608\n",
      "12672\n",
      "12736\n",
      "12800\n",
      "12864\n",
      "12928\n",
      "12992\n",
      "13056\n",
      "13120\n",
      "13184\n",
      "13248\n",
      "13312\n",
      "13376\n",
      "13440\n",
      "13504\n",
      "13568\n",
      "13632\n",
      "13696\n",
      "13760\n",
      "13824\n",
      "13888\n",
      "13952\n",
      "14016\n",
      "14080\n",
      "14144\n",
      "14208\n",
      "14272\n",
      "14336\n",
      "14400\n",
      "14464\n",
      "14528\n",
      "14592\n",
      "14656\n",
      "14720\n",
      "14784\n",
      "14848\n",
      "14912\n",
      "14976\n",
      "15040\n",
      "15104\n",
      "15168\n",
      "15232\n",
      "15296\n",
      "15360\n",
      "15424\n",
      "15488\n",
      "15552\n",
      "15616\n",
      "15680\n",
      "15744\n",
      "15808\n",
      "15872\n",
      "15936\n",
      "16000\n",
      "16064\n",
      "16128\n",
      "16192\n",
      "16256\n",
      "16320\n",
      "16384\n",
      "16448\n",
      "16512\n",
      "16576\n",
      "16640\n",
      "16704\n",
      "16768\n",
      "16832\n",
      "16896\n",
      "16960\n",
      "17024\n",
      "17088\n",
      "17152\n",
      "17216\n",
      "17280\n",
      "17344\n",
      "17408\n",
      "17472\n",
      "17536\n",
      "17600\n",
      "17664\n",
      "17728\n",
      "17792\n",
      "17856\n",
      "17920\n",
      "17984\n",
      "18048\n",
      "18112\n",
      "18176\n",
      "18240\n",
      "18304\n",
      "18368\n",
      "18432\n",
      "18496\n",
      "18560\n",
      "18624\n",
      "18688\n",
      "18752\n",
      "18816\n",
      "18880\n",
      "18944\n",
      "19008\n",
      "19072\n",
      "19136\n",
      "19200\n",
      "19264\n",
      "19328\n",
      "19392\n",
      "19456\n",
      "19520\n",
      "19584\n",
      "19648\n",
      "19712\n",
      "19776\n",
      "19840\n",
      "19904\n",
      "19968\n"
     ]
    }
   ],
   "source": [
    "tic = time.clock()\n",
    "convolutional_neural_network(x_train[:20000], y_train[:20000], x_test, y_test, 64)\n",
    "toc = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic in x_test[:20]:\n",
    "    copyfile(pic, 'breast_cancer_test_data/' + pic.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(x_test_file_path):\n",
    "    # x_test is one data point\n",
    "    # assuming it will be in color too\n",
    "    assert isinstance(x_test_file_path, str)\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "    \n",
    "\n",
    "    image = imread(x_test_file_path)\n",
    "\n",
    "    if np.shape(image) != (50, 50, 3):\n",
    "        image = image.resize((50, 50))\n",
    "\n",
    "    if np.shape(image) != (50, 50, 3):\n",
    "        print('Picture is not in colour!')\n",
    "        raise ManualError\n",
    "    \n",
    "    \n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        model = tf.train.import_meta_graph('conv_nn_breast_cancer.meta')\n",
    "        model.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "        \n",
    "        x_   = loaded_graph.get_tensor_by_name('x:0')\n",
    "        out_ = loaded_graph.get_tensor_by_name('out:0')\n",
    "        \n",
    "        pred_labels = out_.eval({x_: np.array([image])})\n",
    "    \n",
    "    return int(pred_labels[0] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
