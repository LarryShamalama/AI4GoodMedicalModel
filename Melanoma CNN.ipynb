{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time # just to see how fast/slow things run\n",
    "\n",
    "from scipy.misc import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Common_Nevus</th>\n",
       "      <th>Atypical_Nevus</th>\n",
       "      <th>Melanoma</th>\n",
       "      <th>Asymmetry</th>\n",
       "      <th>Pigment_Network</th>\n",
       "      <th>Dots_Globules</th>\n",
       "      <th>Streaks</th>\n",
       "      <th>Regression_Area</th>\n",
       "      <th>Blue-Whitish_Veil</th>\n",
       "      <th>White</th>\n",
       "      <th>Red</th>\n",
       "      <th>Light-Brown</th>\n",
       "      <th>Dark-Brown</th>\n",
       "      <th>Blue-Gray</th>\n",
       "      <th>Black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMD003</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMD009</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMD016</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMD022</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMD024</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_Name Common_Nevus Atypical_Nevus Melanoma  Asymmetry Pigment_Network  \\\n",
       "0     IMD003            X              0        0          0               T   \n",
       "1     IMD009            X              0        0          0               T   \n",
       "2     IMD016            X              0        0          0               T   \n",
       "3     IMD022            X              0        0          0               T   \n",
       "4     IMD024            X              0        0          0               T   \n",
       "\n",
       "  Dots_Globules Streaks Regression_Area Blue-Whitish_Veil White Red  \\\n",
       "0             A       A               A                 A     0   0   \n",
       "1             A       A               A                 A     0   0   \n",
       "2             T       A               A                 A     0   0   \n",
       "3             A       A               A                 A     0   0   \n",
       "4             A       A               A                 A     0   0   \n",
       "\n",
       "  Light-Brown Dark-Brown Blue-Gray Black  \n",
       "0           0          X         0     0  \n",
       "1           X          0         0     0  \n",
       "2           X          X         0     0  \n",
       "3           X          0         0     0  \n",
       "4           X          X         0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melanoma_raw_data = pd.read_csv('./melanoma/melanoma_dataset.csv').fillna(0)\n",
    "melanoma_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard_coded\n",
    "\n",
    "names          = list(melanoma_raw_data['Image_Name'])\n",
    "processed_data = []\n",
    "\n",
    "def transform_1(array):\n",
    "    return list(array == 'X')\n",
    "\n",
    "def transform_2(array):\n",
    "    output = []\n",
    "    \n",
    "    for i in array:\n",
    "        temp = [0, 0, 0]\n",
    "        temp[i] = 1\n",
    "        output.append(temp)\n",
    "    \n",
    "    return np.array(output).T\n",
    "\n",
    "def transform_3(array):\n",
    "    return np.array(array == 'T')\n",
    "\n",
    "def transform_4(array):\n",
    "    output = []\n",
    "    \n",
    "    for i in array:\n",
    "        temp = [0, 0, 0]\n",
    "        \n",
    "        if i == 'A':\n",
    "            temp[0] = 1\n",
    "        elif i == 'AT':\n",
    "            temp[1] = 1\n",
    "        else:\n",
    "            temp[2] = 1\n",
    "            \n",
    "        output.append(temp)\n",
    "            \n",
    "    return np.array(output).T\n",
    "\n",
    "def transform_5(array):\n",
    "    return list(array == 'P')\n",
    "\n",
    "processed_data.append(transform_1(melanoma_raw_data['Common_Nevus']))\n",
    "processed_data.append(transform_1(melanoma_raw_data['Atypical_Nevus']))\n",
    "processed_data.append(transform_1(melanoma_raw_data['Melanoma']))\n",
    "processed_data = np.concatenate((np.array(processed_data), transform_2(melanoma_raw_data['Asymmetry'])))\n",
    "processed_data = np.array(list(processed_data) + [list(transform_3(melanoma_raw_data['Pigment_Network']))])\n",
    "processed_data = np.concatenate((processed_data, transform_4(melanoma_raw_data['Dots_Globules'])))\n",
    "\n",
    "color_one_hot = []\n",
    "\n",
    "for remaining in list(melanoma_raw_data)[-9:-6]:\n",
    "    color_one_hot.append(transform_5(melanoma_raw_data[remaining]))\n",
    "\n",
    "for color in list(melanoma_raw_data)[-6:]:\n",
    "    color_one_hot.append(transform_1(melanoma_raw_data[color]))\n",
    "\n",
    "processed_data = np.concatenate((processed_data, np.array(color_one_hot, dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ['/Users/shamalama/Documents/GitHub/AI4GoodMedicalModel/melanoma/PH2Dataset/PH2 Dataset images/' + img + '/' + img + '_Dermoscopic_Image/' + img + '.bmp' for img in names]\n",
    "y_train = processed_data.T\n",
    "\n",
    "zipped_data = list(zip(x_train, y_train))\n",
    "random.shuffle(zipped_data)\n",
    "\n",
    "N = int(len(x_train)*0.8) # 80% is ratio of training vs. test\n",
    "_x, _y = list(zip(*zipped_data))\n",
    "_x = list(_x)\n",
    "_y = list(_y)\n",
    "\n",
    "x_train = _x[:N]\n",
    "x_test  = _x[N:]\n",
    "y_train = np.array(_y[:N]).reshape(19, -1, 1)\n",
    "y_test  = np.array(_y[N:]).reshape(19, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))\n",
    "\n",
    "def new_conv_layer(input,             \n",
    "                   num_input_channels,\n",
    "                   filter_size,       \n",
    "                   num_filters,  \n",
    "                   name,\n",
    "                   use_pooling=True): \n",
    "\n",
    "    shape   = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    weights = new_weights(shape=shape)\n",
    "    biases  = new_biases(length=num_filters) # one for each filter\n",
    "\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    layer = tf.nn.relu(layer, name=name)\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape  = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer_flat   = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "\n",
    "\n",
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 name,\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(tf.add(tf.matmul(input, weights), biases), name=name)\n",
    "    else:\n",
    "        layer = tf.add(tf.matmul(input, weights), biases, name=name)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def create_batch_tuples(length, batch_size):\n",
    "    output = np.arange(0, length, batch_size)\n",
    "    \n",
    "    if output[-1] != length:\n",
    "        output = np.append(output, length)\n",
    "        \n",
    "    return list(zip(output[:-1], output[1:]))\n",
    "\n",
    "def indicator(array):\n",
    "    return np.concatenate(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x_train, y_train, x_test, y_test, batch_size, number):\n",
    "    '''\n",
    "    x_train is the path of the images\n",
    "    '''\n",
    "    NUM_EPOCHS = 3\n",
    "    \n",
    "    n = len(x_train)\n",
    "    \n",
    "    # dimensions are 100\n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[None, 100, 100, 3], name='x')\n",
    "    y = tf.placeholder(dtype=tf.float32, shape=[None, 1], name='y')\n",
    "    \n",
    "    layer_conv1, weights_conv1 = new_conv_layer(input=x, \n",
    "                                                num_input_channels=3, \n",
    "                                                filter_size=5, \n",
    "                                                num_filters=8, \n",
    "                                                name='layer_conv1')\n",
    "    layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1, \n",
    "                                                num_input_channels=8, \n",
    "                                                filter_size=7, \n",
    "                                                num_filters=32,\n",
    "                                                name='layer_conv2')\n",
    "    layer_flat, num_features = flatten_layer(layer_conv2)\n",
    "    \n",
    "    layer_fc = new_fc_layer(input=layer_flat,\n",
    "                            num_inputs=num_features,\n",
    "                            num_outputs=32,\n",
    "                            name='layer_fc',\n",
    "                            use_relu=True)\n",
    "    \n",
    "    out = new_fc_layer(input=layer_fc,\n",
    "                       num_inputs=32,\n",
    "                       num_outputs=1,\n",
    "                       name='out',\n",
    "                       use_relu=False)\n",
    "    # range of out is \\mathbb{R}^d, with d = 1\n",
    "    \n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=out, labels=y)\n",
    "    cost          = tf.reduce_mean(cross_entropy)\n",
    "    optimizer     = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "    \n",
    "    batch_tuples = create_batch_tuples(len(x_train), batch_size)\n",
    "    x_reshaped   = np.array([np.array(Image.open(pic).resize((100, 100))) for pic in x_train], dtype=np.float32)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for e in range(NUM_EPOCHS):\n",
    "            \n",
    "            global prediction  # for debugging\n",
    "            prediction = []\n",
    "\n",
    "            for (start, end) in batch_tuples:\n",
    "                \n",
    "#                print(start)\n",
    "                \n",
    "                sess.run([optimizer], feed_dict={x: x_reshaped[start: end],\n",
    "                                                 y: y_train[start: end]})\n",
    "        \n",
    "            '''for (start, end) in batch_tuples:\n",
    "                \n",
    "                x_test_reshaped = np.array([imread(pic) for pic in x_test[start: end]])\n",
    "                \n",
    "                batch_preds = list(indicator(out.eval({x: x_test_reshaped})))\n",
    "                prediction += batch_preds\n",
    "                \n",
    "            \n",
    "            accuracy = np.mean(prediction == y_test)\n",
    "            print('Epoch {}, accuracy: {}%'.format(e, np.mean(accuracy)*100))'''\n",
    "        \n",
    "        \n",
    "        batch_tuples_test = create_batch_tuples(len(x_test), batch_size)\n",
    "        x_test_reshaped   = np.array([np.array(Image.open(pic).resize((100, 100))) for pic in x_test], dtype=np.float32)\n",
    "        \n",
    "        y_pred = []\n",
    "        for (start, end) in batch_tuples_test:\n",
    "            \n",
    "            batch_y_pred = out.eval({x: x_test_reshaped[start:end]})\n",
    "            y_pred.append(batch_y_pred)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, './Melanoma_Cnn_' + str(number))\n",
    "        \n",
    "    return np.concatenate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 19 is out of bounds for axis 0 with size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-c08950304db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvolutional_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 19 is out of bounds for axis 0 with size 19"
     ]
    }
   ],
   "source": [
    "num_classes = len(y_train[0])\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for pos in range(19):\n",
    "    print(pos)\n",
    "    y_pred.append(convolutional_neural_network(x_train, y_train[pos], x_test, y_test[pos], 16, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9185889 , -1.3620255 , -6.0662518 , -1.5457033 ,  0.23240742,\n",
       "       -0.25563607, -1.689253  ,  2.7209263 , -0.44664657,  1.543501  ,\n",
       "       -6.7909174 , -1.5091423 , -0.5499488 , -4.9956775 ,  0.54936534,\n",
       "       -3.2218692 , -1.3565081 , -1.1194694 , -3.621114  ], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome = np.array(y_pred).T[0][0]\n",
    "outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9185889, -1.3620255], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaning(outcome):\n",
    "    return np.array([np.argmax(outcome[:3]), # diagnosis\n",
    "                     np.argmax(outcome[3:6]), # asymmetry\n",
    "                     outcome[7] > 0,        # pigment network\n",
    "                     np.argmax(outcome[8:11]),     # dots/globules\n",
    "                     outcome[11] > 0, # streaks\n",
    "                     outcome[12] > 0, # regression areas\n",
    "                     np.argmax(outcome[13:19])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0.],\n",
       "       [0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        1., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0.],\n",
       "       [1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "        0., 1., 1.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        1., 1., 0.],\n",
       "       [0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "        0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 1.],\n",
       "       [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "        0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 0.],\n",
       "       [1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "        1., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1.],\n",
       "       [1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "        0., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 1.],\n",
       "       [1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "        0., 1., 1.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2857142857142857\n",
      "\n",
      "0.5714285714285714\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.5714285714285714\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.14285714285714285\n",
      "\n",
      "0.5714285714285714\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.14285714285714285\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.14285714285714285\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.14285714285714285\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.14285714285714285\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.14285714285714285\n",
      "\n",
      "0.42857142857142855\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.0\n",
      "\n",
      "0.2857142857142857\n",
      "\n",
      "0.14285714285714285\n",
      "\n",
      "0.14285714285714285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(np.array(y_pred).T[0])):\n",
    "    print(np.mean(meaning(np.array(y_pred).T[0][i]) == meaning(y_test.T[0][i])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.argmax(processed_data[:3].T, axis=1)\n",
    "x = processed_data[3:].T\n",
    "\n",
    "zipped_data_for_tree = list(zip(x, y))\n",
    "random.shuffle(zipped_data_for_tree)\n",
    "\n",
    "x_tree, y_tree = list(zip(*zipped_data_for_tree))\n",
    "N_tree = int(len(x_tree)*0.8)\n",
    "x_train_tree = x_tree[N_tree:]\n",
    "y_train_tree = y_tree[N_tree:]\n",
    "x_test_tree = x_tree[:N_tree]\n",
    "y_test_tree = y_tree[:N_tree]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train_tree, y_train_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8875"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(clf.predict(x_test_tree) == y_test_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "def find_index(array, obj):\n",
    "    return list(array).index(obj)\n",
    "\n",
    "print(find_index(np.array(melanoma_raw_data)[:, 0], 'IMD003'))\n",
    "print(find_index(np.array(melanoma_raw_data)[:, 0], 'IMD002'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMD003' 'X' 0 0 0 'T' 'A' 'A' 'A' 'A' 0 0 0 'X' 0 0]\n",
      "['IMD002' 0 'X' 0 1 'AT' 'A' 'A' 'A' 'A' 0 0 'X' 'X' 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(melanoma_raw_data)[0])\n",
    "print(np.array(melanoma_raw_data)[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Image_Name',\n",
       " 'Common_Nevus',\n",
       " 'Atypical_Nevus',\n",
       " 'Melanoma',\n",
       " 'Asymmetry',\n",
       " 'Pigment_Network',\n",
       " 'Dots_Globules',\n",
       " 'Streaks',\n",
       " 'Regression_Area',\n",
       " 'Blue-Whitish_Veil',\n",
       " 'White',\n",
       " 'Red',\n",
       " 'Light-Brown',\n",
       " 'Dark-Brown',\n",
       " 'Blue-Gray',\n",
       " 'Black']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(melanoma_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atypical_Nevus, Asymmetry=1, Pigment_network=Atypical, Dot_globules= Absent, Streaks= Absent, Regression_areas=Absent, Blue_whitish Veil- Absent, color=Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
